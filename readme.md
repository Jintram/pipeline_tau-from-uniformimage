

# Description

For screening purposes, many samples have been imaged, which are measuring a uniform (cell lysate) lifetime signal. 
The goal of this script is to provide an easy way to convert a set of images to a set of lifetimes.

## Installation / dependencies

This script requires the following libraries to be installed:

```
pandas
skimage
numpy
seaborn
matplotlib
adjustText # not essential, only for plotting
```

The script was run on my computer using the environment `2024_FLIM`, which can also be installed completely by downloading and installing the appropriate conda environment using my repository with [conda environments](https://github.com/Jintram/conda-environments).

## Walkthrough

### Input files

The script requires there to be .tif input files generated by LAS-X, where a scaling has been set to 
0-10.000 (the latter number here being ten as I currently understand). Another range could also be chosen,
but then the parameter `CONVERSION_FACTOR` defined in the script needs to be changed.

It is assumed that for sample, there are two measurements, and they can be coupled using the "Sample" and "Condition" 
columns in the metadata file (see below).

### Metadata

The following columns need to be defined in the metadata file:

- **Analysis_ID:** A string that is used later to give output files and dirs a recognizable name.
- **Datadir File:** Directory with data, potentially with subdirectories, which can be defined per sample in the subdir column.
- **Sample:** Sample name, used in plots for identification
- **File:** Tif filename for this sample, without the .tif extension. (.tif extensions are assumed though.)
- **Condition:** For each Sample, it is assumed there are two measurements, which are identified by "Condition". "Condition" should have one of two values, which you can define yourself.
- **Condition_int:** These two conditions should also be represented by integer numbers, ie 0 and 1, in this column.
- **subdir:** See "Datadir"

Example:

| Analysis_ID | Datadir | File | Sample | Condition | Condition_int | subdir |
| ----------- | ------- | ---- | ------ | --------- | ------------- | ------ |
| <analysis_name> | /path/to/data | file_A11_0 | A11 | No reagent | 0 | no_reagent_sample |
|                 | /path/to/data | file_A11_1 | A11 | With reagent | 1 | no_reagent_sample |
| <analysis_name> | /path/to/data | file_A12_0 | A12 | No reagent | 0 | no_reagent_sample |
|                 | /path/to/data | file_A12_1 | A12 | With reagent | 1 | no_reagent_sample |

### Install the script

Clone this repository to your local machine, or download the files. 
Then, take a look at the file

```projects/example_project.py```

Set `LIBSCRIPT_DIR` to the directory you stored the files of this repository in.

### Run an analysis

**To do: further expand this section**

Continue with 

```projects/example_project.py```

Change the parameter `path_sample_metadata` to a metadata file that you created yourself.

Change the parameter `path_outputdir` to an output directory of your liking.

Now run the code line by line.

All data that is generated is stored in the `df_sample_data` file, which is also saved in the output directory (`path_outputdir`).

### Customizing code

**To do: further expand this section**

The above example script `projects/example_project.py` will load code from the file `lib_pipeline_tauimages_getstats.py`.

Once you have initialized the parameters `df_sample_metadata`, `df_sample_data`, you can also open the `lib_pipeline_tauimages_getstats.py` file,
and run code within that file to see what is happening. You can also copy pieces of code from the `lib_pipeline_tauimages_getstats.py` file,
and customize them as you want.
